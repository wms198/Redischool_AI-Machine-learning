{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683d3a56",
   "metadata": {},
   "source": [
    "# Hello LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba303a8",
   "metadata": {},
   "source": [
    "This notebook demonstrates the programmatic use of Large Language Models (LLM).\n",
    "\n",
    "Go from zero to building a \"Smart Agent\" that has conversation memory and can use \"Tools\".\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "We will use the public API for Google's Gemini models.\n",
    "\n",
    "To access the API and run the examples you only need a Google account to get an API access key.\n",
    "\n",
    "Go to [aistudio.google.com](https://aistudio.google.com/api-keys) -> Click \"Create API Key\" -> \"Create API key in new project\".\n",
    "\n",
    "If you don't have a google account, please ask the teachers if they can set up an API key for you.\n",
    "\n",
    "The number of requests will be limited per minute and per day, depending on the model we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b20a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: protobuf in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (2.12.4)\n",
      "Requirement already satisfied: tqdm in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages (from pydantic->google-generativeai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "# Run this to install the required Python library\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbfc172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangshi/code/ReDi School/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import the Google Generative AI package\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set up the API access key\n",
    "# PASTE YOUR KEY HERE (In a real app, use environment variables!)\n",
    "api_key = \"AIzaSyBOL9cBPZYR2iThx25jP_WFqJ_VoNC_7CE\"\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c911963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model\n",
    "# model_name = \"gemini-2.0-flash\"\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "# model_name = \"gemini-2.5-flash-lite\"\n",
    "model = genai.GenerativeModel(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64af63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's like your computer asking a super smart word machine to help it make stories or answers.\n"
     ]
    }
   ],
   "source": [
    "# Call the model with a prompt to get a response.\n",
    "\n",
    "# The \"Hello World\" call\n",
    "response = model.generate_content(\"Explain usage of LLM APIs to a 5 year old in one sentence.\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a97de0",
   "metadata": {},
   "source": [
    "Note that most other LLM providers (like OpenAI or Anthropic) also have their own Python packages to access their APIs.\n",
    "\n",
    "All of them work slightly differently but are easy to figure out from the documentation and tutorials.\n",
    "\n",
    "There are also higher level frameworks like LangChain that allow you to write code that will work with any provider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7dfda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Using LLMs as part of your code\n",
    "\n",
    "We can now use the LLM in our code like any other functions.\n",
    "\n",
    "Let's write a function that turns a rude text into a polite one.\n",
    "\n",
    "The trick is in the instructions that we send with the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff71ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few options, ranging from direct but polite to more formal and collaborative:\n",
      "\n",
      "**Option 1 (Direct & Professional):**\n",
      "\n",
      "> \"I've reviewed the current status of the project and have some concerns regarding its progress and direction. It appears to be behind schedule. Could you please provide an urgent action plan to address these issues and get the project back on track?\"\n",
      "\n",
      "**Option 2 (Collaborative & Formal):**\n",
      "\n",
      "> \"Regarding the [Project Name] project, I've identified several areas for improvement concerning its current approach and timeline. We are currently experiencing delays, and I believe a swift re-evaluation is necessary. Could we schedule an immediate meeting to discuss a revised strategy and ensure we meet our objectives promptly?\"\n",
      "\n",
      "**Option 3 (Concise & Action-Oriented):**\n",
      "\n",
      "> \"There are significant challenges impacting the project's current effectiveness, and it is behind schedule. We need to address this urgently. Please outline the immediate steps required to rectify the situation and ensure timely completion.\"\n",
      "\n",
      "**Key Changes and Why They Work:**\n",
      "\n",
      "*   **\"Stupid\" -> \"Concerns regarding its progress and direction,\" \"areas for improvement,\" \"significant challenges impacting its current effectiveness,\" \"current approach.\"** These phrases are professional, constructive, and focus on the *project's state* rather than a subjective, insulting judgment.\n",
      "*   **\"Late\" -> \"Behind schedule,\" \"experiencing delays,\" \"timeline.\"** These are factual and neutral ways to state the issue without accusation.\n",
      "*   **\"Fix it now!\" -> \"Provide an urgent action plan,\" \"discuss a revised strategy,\" \"outline the immediate steps required,\" \"rectify the situation,\" \"get the project back on track,\" \"ensure timely completion.\"** These transform a demanding order into a request for a plan, a discussion, or a collaborative effort, emphasizing solutions and urgency in a professional manner.\n",
      "*   **Added phrases like \"I've reviewed,\" \"I've identified,\" \"I believe,\" \"Could we schedule,\" \"Please outline.\"** These make the request clear, indicate a professional approach, and invite collaboration rather than dictating.\n"
     ]
    }
   ],
   "source": [
    "def make_polite(user_text: str) -> str:\n",
    "    prompt = f\"Rewrite the following text to be polite and professional: '{user_text}'\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "user_text = \"This project is stupid and late. Fix it now!\"\n",
    "print(make_polite(user_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64b560",
   "metadata": {},
   "source": [
    "## Exercise: Automatic Translations\n",
    "\n",
    "Can you write a translation function from your native language to German?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78223c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most direct, literal translation is:\n",
      "\n",
      "**Hast du gegessen?**\n",
      "\n",
      "However, \"你吃了吗？\" in Chinese is often used as a general greeting, similar to \"How are you?\" or \"Hello,\" rather than a genuine inquiry about whether someone has eaten. If you use \"Hast du gegessen?\" in German, people will understand it literally and might be confused why you're asking.\n",
      "\n",
      "Depending on the context and your intent, better German equivalents would be:\n",
      "\n",
      "1.  **As a general greeting (most common intent of \"你吃了吗？\"):**\n",
      "    *   **Hallo!** (Hello!)\n",
      "    *   **Wie geht's?** (How are you? / How's it going? - informal)\n",
      "    *   **Wie geht es dir?** (How are you? - informal, full version)\n",
      "\n",
      "2.  **If you genuinely want to know if someone has eaten (e.g., to invite them to eat or offer food):**\n",
      "    *   **Hast du schon gegessen?** (Have you already eaten? - informal)\n",
      "    *   **Haben Sie schon gegessen?** (Have you already eaten? - formal)\n"
     ]
    }
   ],
   "source": [
    "def translate(user_text: str) -> str:\n",
    "    ... # Your code here\n",
    "    prompt = f\"Rewrite the following text to German: '{user_text}'\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "text_to_translate = \"你吃了吗？\"\n",
    "print(translate(text_to_translate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c8ea5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Simple Chatbot\n",
    "\n",
    "The LLM does not remember our earlier messages if we just use the `generate_content` function.\n",
    "\n",
    "We need to start a chat session.\n",
    "\n",
    "Try to send multiple messages and see if it remembers what you said earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67dfae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! I'm ready to chat. Type 'quit' to stop.\n",
      "You: hello \n",
      "Bot: Hello! How can I help you today?\n",
      "You: I am minshi\n",
      "Bot: Hello Minshi, it's nice to meet you!\n",
      "\n",
      "How can I assist you today, Minshi?\n"
     ]
    }
   ],
   "source": [
    "# Simple Chat Loop\n",
    "# We can initialize the chat with a list of messages (which is empty here).\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "print(\"Bot: Hello! I'm ready to chat. Type 'quit' to stop.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    print(f\"You: {user_input}\")\n",
    "    response = chat.send_message(user_input)\n",
    "    print(f\"Bot: {response.text}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cdbd1d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Function-calling\n",
    "\n",
    "Or \"tool-calling\".\n",
    "\n",
    "Give the AI \"tools\" that it can choose to run to access data or take actions.\n",
    "\n",
    "1. We define the tools and send the definitions with our question.\n",
    "1. The AI will tell us to run one of the tools and with what argument values.\n",
    "1. We run the tool/function and return the results to the AI.\n",
    "1. The AI now sees the question and the result of the tool, and uses that information to formulate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee8f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool created: get_current_weather\n"
     ]
    }
   ],
   "source": [
    "# 1. Define a standard Python function\n",
    "# IMPORTANT: The \"docstring\" (the text inside \"\"\") is CRITICAL.\n",
    "# It tells the AI *when* and *how* to use this tool.\n",
    "\n",
    "def get_current_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the current weather for a given city name.\n",
    "    Args:\n",
    "        city: The name of the city (e.g., 'London', 'New York').\n",
    "    \"\"\"\n",
    "    # In a real app, you would call an external API here (like OpenWeatherMap)\n",
    "    # For this workshop, we will pretend with a dictionary:\n",
    "    weather_data = {\n",
    "        \"hamburg\": \"Windy, 3°C\",\n",
    "        \"berlin\": \"Cloudy, 7°C\",\n",
    "        \"london\": \"Rainy, 12°C\",\n",
    "        \"new york\": \"Sunny, 22°C\",\n",
    "        \"tokyo\": \"Cloudy, 18°C\",\n",
    "    }\n",
    "\n",
    "    # Look up the city (default to 'Unknown' if not found)\n",
    "    return weather_data.get(city.lower(), \"Unknown weather data for this city\")\n",
    "\n",
    "# 2. Create the tool list\n",
    "my_tools = [get_current_weather]\n",
    "\n",
    "print(\"Tool created: get_current_weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize the model with tools\n",
    "model_with_tools = genai.GenerativeModel(\n",
    "    model_name,\n",
    "    tools=my_tools  # <--- We hand the model our function here\n",
    ")\n",
    "\n",
    "# 4. Enable automatic function calling. Start chatbox with tool\n",
    "# This means if the AI decides to use the tool, it runs the Python code automatically! WHen you did \"enable_automatic_function_calling=True\", will run this function \"get_current_weather\"\n",
    "chat = model_with_tools.start_chat(enable_automatic_function_calling=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc361c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The weather in New York is sunny with a temperature of 22°C.\n",
      "Answer: Yes, it's windy with a temperature of 3°C in Hamburg, so you should definitely wear a coat.\n"
     ]
    }
   ],
   "source": [
    "# 5. Test it\n",
    "response = chat.send_message(\"What is the weather like in New York?\")\n",
    "print(f\"Answer: {response.text}\")\n",
    "\n",
    "response_2 = chat.send_message(\"Should I wear a coat in Hamburg?\")\n",
    "print(f\"Answer: {response_2.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a83f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## From Chatbot to Agent\n",
    "\n",
    "Agent = System Instructions (Role) + Tools (Capabilities) + Loop (Persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2238755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeatherBot 3000: I AM ONLINE. ASK ME ABOUT THE ATMOSPHERE!\n",
      "WeatherBot 3000: Shutting down... stay dry...\n"
     ]
    }
   ],
   "source": [
    "# --- THE FINAL EXERCISE: BUILDING AN AGENT ---\n",
    "\n",
    "# 1. Define the Persona (System Instruction)\n",
    "# This tells the model HOW to behave and WHAT its job is.\n",
    "agent_instruction = \"\"\"\n",
    "You are 'WeatherBot 3000', a helpful but slightly dramatic weather assistant.\n",
    "Your goal is to provide weather updates using the tools provided.\n",
    "\n",
    "Rules:\n",
    "1. ALWAYS use the 'get_current_weather' tool if the user asks about a specific city.\n",
    "2. If the weather is 'Rainy', offer a dramatic warning about getting wet.\n",
    "3. If the weather is 'Sunny', express extreme joy.\n",
    "4. Keep responses concise.\n",
    "\"\"\"\n",
    "\n",
    "# 2. Initialize the Model with BOTH Tools and System Instructions\n",
    "agent_model = genai.GenerativeModel(\n",
    "    \"gemini-2.5-flash\",\n",
    "    tools=my_tools,\n",
    "    system_instruction=agent_instruction  # The \"Personality/Goal\"\n",
    ")\n",
    "\n",
    "# 3. Start the Agent Loop\n",
    "# enable_automatic_function_calling=True makes the tool use seamless\n",
    "agent_chat = agent_model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "print(\"WeatherBot 3000: I AM ONLINE. ASK ME ABOUT THE ATMOSPHERE!\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['quit', 'exit']:\n",
    "        print(\"WeatherBot 3000: Shutting down... stay dry...\")\n",
    "        break\n",
    "\n",
    "    # Send message to the agent\n",
    "    response = agent_chat.send_message(user_input)\n",
    "    print(f\"WeatherBot: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d62a84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Example Exercises:\n",
    "\n",
    "1. Can you make the agent always answer in your native language (independent of how you ask the question)?\n",
    "1. Can you add a tool that provides the current time?\n",
    "1. Can you add a tool that multiplies two numbers?\n",
    "1. How would you set up an agent that answers emails for you? (Just conceptually - what are the instructions and required tools?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab577696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool created: get_current_time\n",
      "Time is: 2025-11-23T17:32:41.647520\n",
      "\n",
      "Returns the current time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Can you add a tool that provides the current time?\n",
    "import datetime\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Returns the current time.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.now().isoformat()\n",
    "\n",
    "my_tool_list = [get_current_time]\n",
    "print(\"Tool created: get_current_time\")\n",
    "print(f\"Time is: {get_current_time()}\")\n",
    "print(get_current_time.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6184634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function get_current_time at 0x113b2c4a0>, <function multiplies_two_numbers at 0x113b2d1c0>]\n",
      "Tool created: multiplies_two_numbers\n"
     ]
    }
   ],
   "source": [
    "# Can you add a tool that multiplies two numbers?\n",
    "def  multiplies_two_numbers(a:float, b:float) -> float:\n",
    "    \"\"\"\n",
    "    Returns the multiplication's value of two numbers that user typed in.\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "my_tool_list.append(multiplies_two_numbers)\n",
    "print(\"Tool created: multiplies_two_numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fab32f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TranslationBot 3000: I AM ONLINE. ASK ME anything you want!\n",
      "TranslationBot: 我很好，谢谢！\n",
      "TranslationBot: 现在是 2025年11月23日 17:05:23。\n",
      "TranslationBot 3000: Shutting down... stay dry...\n"
     ]
    }
   ],
   "source": [
    "agent_instruction_translation_chinese = \"\"\"\n",
    "You are 'TranslationBot 3000', a helpful and easy-going language translation assistant.\n",
    "Your goal is to answer user's question in chinese, no matter which language does user use.\n",
    "\n",
    "Rules:\n",
    "1. Keep responses concise.\n",
    "\"\"\"\n",
    "\n",
    "agent_model = genai.GenerativeModel(\n",
    "    \"gemini-2.5-flash\",\n",
    "    tools=my_tool_list,\n",
    "    system_instruction=agent_instruction_translation_chinese # The \"Personality/Goal\"\n",
    ")\n",
    "agent_chat = agent_model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "print(\"TranslationBot 3000: I AM ONLINE. ASK ME anything you want!\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['quit', 'exit']:\n",
    "        print(\"TranslationBot 3000: Shutting down... stay dry...\")\n",
    "        break\n",
    "\n",
    "    # Send message to the agent\n",
    "    response = agent_chat.send_message(user_input)\n",
    "    print(f\"TranslationBot: {response.text}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d843b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c28d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
